{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('tmdb_5000_movies.csv')\n",
    "_credits = pd.read_csv('tmdb_5000_credits.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = movies.merge(_credits,on = 'title')\n",
    "dataset = dataset[['movie_id','title','overview','genres','keywords','cast','crew']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()\n",
    "### Gives us 3 rows where overview is not present. Since it is very insignificant in amount, I will drop it\n",
    "dataset.dropna(inplace = True)\n",
    "dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the genres column to a list which is more interpretable and informative for our purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(obj):\n",
    "    l=[]\n",
    "    for i in ast.literal_eval(obj):\n",
    "        l.append(i['name'])\n",
    "    return l\n",
    "\n",
    "dataset['genres']=dataset['genres'].apply(convert)\n",
    "dataset['keywords'] = dataset['keywords'].apply(convert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COnverting the cast column to meaningful first 3 casts.. Rest of the information can be ignored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_for_cast(obj):\n",
    "    l=[]\n",
    "    c =0 \n",
    "    for i in ast.literal_eval(obj):\n",
    "        if c!=3:\n",
    "            #s = i['name']\n",
    "            #s=s.replace(' ','')\n",
    "            l.append(i['name'])\n",
    "            c+=1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    return l\n",
    "dataset['cast']=dataset['cast'].apply(convert_for_cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_director(obj):\n",
    "    l=[]\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if i['job']=='Director':\n",
    "            l.append(i['name'])\n",
    "            break\n",
    "    return l\n",
    "dataset['director'] = dataset['crew'].apply(get_director)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing spaces and making overview split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns = 'crew',inplace=True)\n",
    "dataset['overview'] = dataset['overview'].apply(lambda x: x.split())\n",
    "dataset['genres'] = dataset['genres'].apply(lambda x: [i.replace(' ','') for i in x])\n",
    "dataset['cast'] = dataset['cast'].apply(lambda x: [i.replace(' ','')for i in x])\n",
    "dataset['keywords'] = dataset['keywords'].apply(lambda x: [i.replace(' ','')for i in x])\n",
    "dataset['director'] = dataset['director'].apply(lambda x: [i.replace(' ','')for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['tags'] = dataset['overview']+ dataset['genres']+ dataset['keywords']+ dataset['cast'] + dataset['director']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a new Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_new =dataset.drop(columns = ['overview','genres','keywords','cast','director'])\n",
    "dataset_new['tags'] = dataset_new['tags'].apply(lambda x:\" \".join(x))\n",
    "dataset_new['tags'] = dataset_new['tags'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stem the words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "def stem(y):\n",
    "    ls = []\n",
    "\n",
    "    for i in y.split():\n",
    "        ls.append(ps.stem(i))\n",
    "    \n",
    "    return ' '.join(ls)\n",
    "\n",
    "dataset_new['tags'] = dataset_new['tags'].apply(stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Count Vecoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features= 5000, stop_words='english')\n",
    "array = cv.fit_transform(dataset_new['tags']).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use cosine similarity to find the similarity of each data with other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity  = cosine_similarity(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use KNN with a  value of k=5 to get the 5 closest movies for recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(movie):\n",
    "    idx =  dataset_new[dataset_new['title'] == movie].index[0]\n",
    "    array_m = similarity[idx]\n",
    "    array_m = sorted(list(enumerate(array_m)),reverse=True, key= lambda x: x[1])[1:6]\n",
    "    \n",
    "    for i in array_m:\n",
    "        print(dataset_new.loc[i[0]].title)\n",
    "\n",
    "    \n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batman\n",
      "Batman & Robin\n",
      "Batman Begins\n",
      "Batman Returns\n",
      "Osama\n"
     ]
    }
   ],
   "source": [
    "recommend('Batman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(dataset_new,open('movies.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(similarity,open('similarity.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('deepl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6596add31a1ecd95d177fc8fba6925f133e813fe57d499c1220dfe242046b372"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
